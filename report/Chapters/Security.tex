%************************************************
\chapter{Security Analysis}\label{ch:security}
%************************************************

This chapter presents a security analysis for the protocol proposed in the previous chapter. This chapter will prove that our authentication protocol achieves injective agreement (IA).
In protocol verification, two models are commonly used for proving properties~\cite{blanchet2012security}:

\begin{itemize}
    \item In the computational model, we consider passive probabilistic polynomial-time adversaries limited to certain observed information. In the computational model, proofs are often manual, and we say that a given security property holds, if the probability that it does not, is negligible in a security parameter.
   
   \item In the symbolic model (or Dolev-Yao model~\cite{dolev1983security}), we consider active adaptive adversaries  that can observe, intercept and synthesize new messages.
   Cryptographic primitives are represented as function symbols, and messages as composite terms of these symbols.
   Proofs are often automated essentially by generating the set of all information an adversary could possibly know, and security properties are proven under the assumption that the primitives are unbreakable and non-malleable.
   
\end{itemize}
   
    

An attack found in the symbolic model will also yield an attack in the computational model. However, an attack in the computational model might not be found in the symbolic model~\cite{blanchet2012security}.

We will use the computation model for crypto analysis to prove against attacks that break the protocol by breaking the underlying cryptographic primitives, and the symbolic model for logical analysis to prove against attacks such as man-in-the-middle, replay and reflection attacks. 

%It could for example be the case that some attack can be carried out with some probability greater than negligible in the computational model, and is therefore not found in the symbolic model because the primitives are assumed to be perfectly secure. Conversely, computational proves are (often) manual, while symbolic proves are automated, essentially by generating the set of all information an adversary could possible know.

\begin{comment}
\begin{itemize}

    \item An adversary should not be able to forge evidence of identity without compromising the secrets of both \gls{authenticator} and \gls{sibling}.
    
    \item Hijacking an active session or token should not give the \gls{adversary} unauthorized access for longer than the session is actively kept alive by the \gls{server} and \gls{authenticator}.
    
\end{itemize}
\end{comment}

\section{Security in the Computational Model}

A prerequisite of injective agreement is that evidence of identity is unforgeable.

\begin{definition}[Unforgeability]
For all challenges, without knowing the pertinent secrets, an adversary $\mathcal{A}$ should not be able to forge a response that the \gls{server} will accept as valid.
\end{definition}

This property is strongly related to the underlying cryptographic primitives, and we have therefore chosen to prove unforgeability in a computational model. The above definition is moreover very strong, and is not in a provable form for the computational model. We will therefore in the following section state very precise definitions of when we consider unforgeability to be broken, and prove unforgeability for different levels of observable information.

\subsection{Weak External Observation}
Let us start by defining a \textit{simulator} of our protocol.
\begin{definition}[Weak external observation] 
Let $Sim^{weo}_\mathcal{C}(\cdot)$ denote a simulator of our protocol that outputs challenge and response pairs $(c, n)$. 
\end{definition}

The purpose of this definition is to be able to model the view of an adversary $\mathcal{A}$ observing, or eavesdropping, rounds of authentication. This particular definition corresponds to the view of an adversary capable of eavesdropping the communication between a \gls{client} and a \gls{server}. 

\begin{definition}[Registration]
Let $Register(\cdot)$ denote an algorithm that on input of a security parameter $1^n$ runs some generate primitive and outputs a public-key $pk$, and a set of corresponding private-keys $sk$ with $\lvert sk \rvert = 2$.
\end{definition}

In this section we consider only the authentication part of our protocol, and therefore model registration as an atomic operation. In practice that is not the case. This we be revisited in the discussion.

With these definitions in place, given an adversary $\mathcal{A}$, consider the following experiment:

\vspace{1em}
\noindent\textbf{Unforgeability experiment $Forge^{weo}_{\mathcal{A}, \mathcal{C}}(n)$:}
\begin{enumerate}

    %\item A cyclic group $d = \langle \mathbb{G}, q, g \rangle$ is generated by running $\mathcal{G}(1^n)$, and then run $\langle pk, sk \rangle \leftarrow Register(d)$.
    
    %\item Two public-private-key sets $\left\{ \langle x_A,y_A \rangle, \langle x_{As}, y_{As} \rangle \right\}$ are generated respectively by running $Gen'(d)$, and a joint public-key is computed as $y := y_A \times y_{As}$
    
    
    \item $Register(1^n)$ is run to obtain keys $(pk, sk)$.
    
    \item The adversary $\mathcal{A}$ is given the public-key $pk$, and access to a simulator $Sim^{weo}_\mathcal{C}(\cdot)$. %Let $\mathcal{Q}$ denote the set of queries to the simulator.
    
    \item The adversary is eventually given $c \leftarrow enc(n,pk)$, with $n$ being an arbitrary value of $\mathbb{G}$, and outputs $n'$.
    
    \item $\mathcal{A}$ succeeds if and only if $n = n'$.
    %and (2) $\langle c, n \rangle \notin \mathcal{Q}$.
    In this case the output of the experiment is defined to be 1.
\end{enumerate}


\begin{proposition}\label{proposition:ex-forge}
Our authentication protocol $\mathcal{C}$ has unforgeability if for all probabilistic polynomial-time adversaries $\mathcal{A}$ capable of weak external observation, there is a negligible function $negl$ such that
{\setlength{\mathindent}{0cm}
\begin{align*}
&&    Pr\left[ Forge^{weo}_{\mathcal{A}, \mathcal{C}}(n)  = 1 \right] \leq negl(n) 
\end{align*}}
\end{proposition}

\begin{proof}
 An adversary $\mathcal{A}$ for $Forge^{weo}_{\mathcal{A}, \mathcal{C}}(n)$ can be used to construct an adversary $\mathcal{A'}$ for the eavesdropping indistingushability experiment $PubK^{eav}_{\mathcal{A'}, \Pi}(n)$, where $\Pi$ is standard ElGamal as defined in the previous chapter. The adversary can be constructed in the following way:\newline

\textbf{Adversary $\mathcal{A}'$:}
\begin{enumerate}
    \item On input of an ElGamal public-key $pk := \langle \mathbb{G}, q, g, y \rangle$, call $\mathcal{A}$ with $pk$ and a simulator $Sim^{weo}_\mathcal{C}(\cdot)$, and output two arbitrary messages $m_1, m_2 \in \mathbb{G}$.
    \item On queries to the simulator, select an arbitrary $n \in \mathbb{G}$, compute $c \leftarrow enc(n,pk)$, and return $(c, n)$.
    \item On input of a ciphertext $c \leftarrow enc(m_b, pk)$, call $\mathcal{A}(c)$.
    \item If $\mathcal{A}$ outputs $m_0$, then output $0$, if it outputs $m_1$, then output $1$, otherwise choose arbitrarily.
\end{enumerate}


For a public-key encryption scheme to be indistinguishable in the presence of an eavesdropper, then the probability must be:
{\setlength{\mathindent}{0cm}
\begin{align*}
&& Pr\left[ PubK^{eav}_{\mathcal{A'}, \Pi}(n)  = 1 \right] \leq \frac{1}{2} + negl(n)
\end{align*}}

However, if an adversary $\mathcal{A}$ exists that succeeds in $Forge^{weo}_{\mathcal{A}, \Pi}(n)$ with probability greater than $negl(n)$, then the probability of the adversary $\mathcal{A}'$ succeeding in $PubK^{eav}_{\mathcal{A'}, \Pi}(n)$ would be:
{\setlength{\mathindent}{0cm}
\begin{align*}
&& Pr\left[ PubK^{eav}_{\mathcal{A'}, \Pi}(n)  = 1 \right] = \frac{1}{2} + Pr \left[ Forge^{weo}_{\mathcal{A}, \mathcal{C}}(n)  = 1 \right] \not\leq \frac{1}{2} + negl(n)
\end{align*}}

Since ElGamal is proven to be indistinguishable in the presence of an eavesdropper (\acrshort{cpa}-secure)~\cite[page 402]{katz2014introduction}, under the assumption that the DDH problem is hard, then by reduction, proposition~\ref{proposition:ex-forge} also holds under the DDH assumption.
\end{proof}

This proof shows that for all PPT adversaries capable of weak external observation; meaning adversaries capable of eavesdropping on the communication between \gls{client} and \gls{server}; they will not be able to forge a valid response to a challenge.

\subsection{Weak Internal Observation}

Lets now consider a slightly different experiment, where adversaries are capable of weak internal observation. 
This means that they are \textit{also} capable of obtaining private-keys.

\begin{definition}
Let $LtkReveal(\cdot)$ denote a private-key oracle that can be queried for private-keys in the set $sk$.
\end{definition}

With this definition the unforgeability experiment for adversaries capable of \textit{Weak Internal Observation} is given as:

% First we fix $Register(\cdot)$ to on input of a security paramter $1^n$, obtain a cyclic group $d= \langle \mathbb{G}, q, g \rangle$ by running $\mathcal{G}(1^n)$, then generate two key-sets $\langle x_A,y_A \rangle$ and $ \langle x_{As}, y_{As} \rangle$ using $Gen'(d)$, compute $y = y_A \times y_{As}$, and finally output the public-key $pk := \langle \mathbb{G}, q, g, y \rangle$.

\vspace{1em}
\noindent\textbf{Unforgeability experiment $Forge^{wio}_{\mathcal{A}, \mathcal{C}}(n)$:}
\begin{enumerate}

    %\item A cyclic group $d:= \langle \mathbb{G}, q, g \rangle$ is generated by running $\mathcal{G}(1^n)$.
    
    %\item Two public-private-key sets $\left\{ \langle x_A,y_A \rangle, \langle x_{As}, y_{As} \rangle \right\}$ are generated respectively by running $Gen'(d)$, and a joint public-key is computed as $y := y_A \times y_{As}$

    %\item A cyclic group $d = \langle \mathbb{G}, q, g \rangle$ is generated by running $\mathcal{G}(1^n)$, and then a public-key is obtained by running $pk \leftarrow Register(d)$.
    
    \item $Register(1^n)$ is run to obtain keys $(pk, sk)$.

    \item The adversary $\mathcal{A}$ is given the public-key $pk$, access to a simulator $Sim^{weo}_\mathcal{C}(\cdot)$, and access to a key oracle $LtkReveal(\cdot)$. Let $\mathcal{K}$ denote the set of queries to the key oracle.
    
    \item The adversary is eventually given $c \leftarrow enc(n,pk)$, with $n$ being an arbitrary value of $\mathbb{G}$, and outputs $n'$.
    
    \item $\mathcal{A}$ succeeds if and only if (1) $n = n'$, and (2) $sk \nsubseteq \mathcal{K}$. In this case the output of the experiment is defined to be 1.
    
\end{enumerate}

This experiment entails, that even in possession of some proper subset of the private-keys, then the adversary is not capable of forging a valid response.

\begin{proposition}\label{conjecture:forge-rev-ex}
Our authentication protocol $\mathcal{C}$ has unforgeability if for all probabilistic polynomial-time adversaries $\mathcal{A}$ capable of weak internal observation, there is a negligible function $negl$ such that
{\setlength{\mathindent}{0cm}
\begin{align*}
&&    Pr\left[ Forge^{wio}_{\mathcal{A}, \mathcal{C}}(n)  = 1 \right] \leq negl(n) 
\end{align*}}
\end{proposition}

It should be clear from the experiment and proposition that if Distributed ElGamal is CPA-secure, even when a key is leaked, then the above proposition holds. It follows that for Distributed ElGamal, no party (neither an honest party) with a proper subset of keys should be able to distinguish ciphers, otherwise it would not be a functioning partial encryption system.

%ElGamal can be proven to be CPA-secure by showing that an adversary $\mathcal{A}$ for the eavesdropping indistinguishability experiment can be used to construct an adversary $\mathcal{A'}$ for the DDH problem~\cite[page 402]{katz2014introduction}, and by reduction, ElGamal can be proved CPA secure under the DDH assumption.
%The exact same reduction can be made for Distributed ElGamal proving it CPA-security.

Although a formal proof is omitted for brevity, for a Distributed ElGamal cipher $(\alpha, \beta)$, consider the alpha:
{\setlength{\mathindent}{0cm}
\begin{align*}
&&    \alpha = m  y^r = m \left(g^{x_1 + x_2}\right)^r = m \cdot g^{rx_1} \cdot g^{rx_2}
\end{align*}}
If the adversary knows $x_1$, then the cipher can be reduced as follows:
{\setlength{\mathindent}{0cm}
\begin{align*}
&&  \frac{m \cdot g^{rx_1} \cdot g^{rx_2}}{\beta^{x_1}} = m \cdot g^{rx_2}
\end{align*}}

The reduction leaves us with exactly the cipher of the encryption $Enc(m,y_2) \rightarrow (m \cdot g^{rx_2}, g^r)$. Intuitively, if an adversary can recover $m$ knowing $x_1$ for a Distributed ElGamal cipher, then the adversary can also break standard ElGamal. \hfill $\square$

%Providing a probabilistic proof for this is outside our scope. However, it should be clear that if we assume that Distributed ElGamal is still indistinguishable when leaking only one of the secret keys $sk_i$, and thus when given a partial decryption oracle $Dec'_{sk_i}(\cdot)$, then the above proposition holds. \citet{brandt2005efficient} states this conjecture to be true, but does not provide an in-depth proof. 

\subsection{Strong External Observation}
In this section, we extend the adversaries capabilities to include strong external observation; that is, the capability of listening to \textit{all} communication between actors in the protocol (as shown in figure~\ref{msc:auth}). For generality, we do not fix the actor who publishes its partial decryption, but just note the publishing party as $i$.

\begin{definition}[strong external observation] 
Let $Sim^{seo}_\mathcal{C}(\cdot)$ denote a simulator of our protocol that outputs challenge, partial decryption, and response tuples $\langle c, c'_{i}, n \rangle$.
\end{definition}

We define a new experiment $Forge^{seo}_{\mathcal{A}, \mathcal{C}}$, to be the same as $Forge^{weo}_{\mathcal{A}, \mathcal{C}}$, except that the simulator used is now $Sim^{seo}_\mathcal{C}(\cdot)$, and the adversary is also given $c'_i = Dec'(c, sk_{i})$ with $sk_i \in sk$ in step 3.

\begin{proposition}\label{proposition:forge-in}
Our authentication protocol $\mathcal{C}$ has unforgeability if for all probabilistic polynomial-time adversaries $\mathcal{A}$ capable of strong external observation, there is a negligible function $negl$ such that
{\setlength{\mathindent}{0cm}
\begin{align*}
&&    Pr\left[ Forge^{seo}_{\mathcal{A}, \mathcal{C}}(n)  = 1 \right] \leq negl(n) 
\end{align*}}
\end{proposition}

\begin{collary}
If proposition~\ref{conjecture:forge-rev-ex} holds, then proposition~\ref{proposition:forge-in} also holds.
\end{collary}

\begin{proof}
An adversary $\mathcal{A}$ for $Forge^{seo}_{\mathcal{A}, \mathcal{C}}(n)$, can be used to construct an adversary $\mathcal{A'}$ for  $Forge^{wio}_{\mathcal{A'}, \mathcal{C}}(n)$ in the following way:
\newline

\textbf{Adversary $\mathcal{A}'$:}
\begin{enumerate}
    \item On input of a public-key $pk$, a simulator $Sim^{weo}_\mathcal{C}(\cdot)$, and a key oracle $LtkReveal(\cdot)$, call $\mathcal{A}$ with $pk$ and a new simulator $Sim^{seo}_\mathcal{C}(\cdot)$.
    
    \item Query the key oracle for some private-key $sk_i := LtkReveal(i)$.
    
    \item On queries to the simulator $Sim^{seo}_\mathcal{C}(\cdot)$, query $Sim^{weo}_\mathcal{C}(\cdot)$ for $( c,n )$. Then compute $c'_{i} := Dec'(c,sk_{i})$ and output $( c, c'_{i}, n )$.
    
    \item On input of a ciphertext $c$, compute $c'_i = Dec'(c,sk_{i})$, and then output $\mathcal{A}(c,c'_i)$.
\end{enumerate}

In all cases where the adversary $\mathcal{A}$ succeeds, $\mathcal{A'}$ also succeeds. If there exists no PPT adversary $\mathcal{A'}$ that succeeds with better than negligible probability, then there can exist no PPT adversary $\mathcal{A}$ that succeeds with better than negligible probability
{\setlength{\mathindent}{0cm}
\begin{align*}
&& Pr\Bigl[ Forge^{seo}_{\mathcal{A}, \mathcal{C}}(n)  = 1 \Bigr] \leq Pr\left[ Forge^{wio}_{\mathcal{A'}, \mathcal{C}}(n)  = 1 \right] \leq negl(n)
\end{align*}}
\end{proof}

\begin{comment}
Informally, under the assumption that publishing a partial decryption of a cipher  increases the probability of indistinguishable for any PPT adversary at most negligible
{\setlength{\mathindent}{0cm}
\begin{align*}
&& \Bigl| Pr\left[ PubK^{eav}_{\mathcal{A'}, \Pi}(n)  = 1 \right]  - Pr\left[ PubK^{eav}_{\mathcal{A'}, \Pi'}(n)  = 1 \right] \Bigr| \leq negl(n)
\end{align*}}
where $\Pi$ is ElGamal, and $\Pi'$ is Distributed ElGamal, then our protocol has unforgeability under internal observation. We have not been able to find a proof for above equation, but given that the probability of distinguishing a cipher from a partially decrypted cipher is negligible under the DDH assumption~\cite[page 321]{katz2014introduction}, then we find this to be a reasonable assumption.
\end{comment}

\subsection{Strong Internal Observation}

Let us consider a last unforgeability experiment. We define $Forge^{sio}_{\mathcal{A}, \mathcal{C}}$, to be the same as $Forge^{wio}_{\mathcal{A}, \mathcal{C}}$, except that the simulator used is now $sim^{seo}_\mathcal{C}(\cdot)$, and the adversary is also given $c'_i = Dec'(c, sk_{i})$ with $sk_i \in sk$ in step~3.

%This reflects the actual information that an adversary who compromised the \gls{authenticator} has available, as the \gls{sibling} outputs its partial decryption. This should be clear from figure~\ref{msc:auth}.

\begin{proposition}\label{proposition:forge-rev-in}
Our authentication protocol $\mathcal{C}$ has unforgeability if for all probabilistic polynomial-time adversaries $\mathcal{A}$ capable of strong internal observation, there is a negligible function $negl$ such that
{\setlength{\mathindent}{0cm}
\begin{align*}
&&    Pr\left[ Forge^{sio}_{\mathcal{A}, \mathcal{C}}(n)  = 1 \right] \leq negl(n) 
\end{align*}}
\end{proposition}

This proposition can be trivially disproved and lead us to the first known attack on our protocol. As the adversary is given given both $c \leftarrow enc(n, pk)$ and $c' = Dec'(c, sk_{i})$ in step 3, and has access to $LtkReveal(\cdot)$, he can simply retrieve the missing key, and then recover $n$ thus succeeding \textit{every} time.

If an adversary obtains the key of the authenticator and can communicate with the sibling, then the attack can be mounted in practice. This is a problem since \textit{Resilient-to-Internal-Observation} (as presented in the design section), is one of our design goals, and is not granted if compromising one of two devices can break the scheme~\cite{bonneau2012quest}.

\section{Security in the Symbolic Model}~\label{sec:tamarin}
In this section, we consider adversaries capable of not only internal observation and compromising keys, but also capable of adaptively intercept and synthesize messages. We have already shown that our protocol does not have unforgeability under strong internal observation. Here we however show that if messages between \gls{authenticator} and \gls{sibling} is authentic, then
our protocol has both unforgeability under internal observation and achieves injective agreement. Furthermore, we show that unless the adversary obtains both distributed keys, then either \gls{authenticator} or \gls{sibling} was involved in the authentication run.

\subsection{The Tamarin Prover}
Tamarin is a symbolic verification tool specialized for security protocols~\cite{meier2013tamarin}. Tamarin is designed to prove trace properties. A trace property holds if for all possible instances of the model, a given trace does or does not exist, and can therefore be used to prove properties such as secrecy (where the adversary in no possible instances of the model can obtain a secret value) and authentication (where for all traces some set of events occurred).

Rules in tamarin are written as $l \ifarrow[a] r$, where $l$ is a set of inputs, $a$ is a set of events, and $r$ is a set of outputs. If $a$ is empty then the brackets are omitted. The predefined predicates $In$ and $Out$ are used to pass information between rules. Furthermore $Fr({\sim}m)$ is a predicate that outputs a new fresh message $m$, and a message taken as input can be restricted to be fresh by prepending ${\sim}$. Messages prepended with $\$$ symbolizes public terms and is commonly used to establish actors identity. Lastly, custom in- and outputs can be defined by creating new predicates, such as $Server(\$S, {\sim}n)$. A rule with this predicate in its output set, outputs the identity $\$S$ and a fresh value ${\sim}n$ for other rules to consume. As an actor's behavior is typically split into several rules, these predicates can be used to persist state or pass data between rules, that should not be directly available to the adversary. If a predicate is prepended with $!$, then the output is persisted, where it is otherwise consumed when retrieved.

Functions can be applied to messages or terms. For example hashing a message $m$ by applying the function $h/1$, yields a new term $h(m)$. The term is considered as an atomic unit, and inner values can only be retrieved if allowed by a rule $In(h(m)) \ifarrow Out(m)$, or equation $h(m) \simeq m$.

\subsection{Modeling our Protocol in Tamarin}
In this section we are modeling on a higher abstraction level than in the previous section. In the previous section, we proved certain properties based on the probability of breaking the underlying cryptographic primitives. This section, will utilize symbolic verification and the underlying primitives are therefore assumed to be unbreakable. The following presents the model. The full code version is listed in appendix~\ref{ch:tamarin}.

\subsection{Equational Theory}
The primitives are modeled as a set of functions; $enc$, $dec$, $pdec$, $plus$, $comb$ and $pk$, and an equational theory.
\begin{align*}
    &dec\left(enc\left(m,pk\left(sk\right)\right),sk\right) \simeq m\\
    &comb\left(pk\left({\sim}sk1\right),pk\left({\sim}sk2\right)\right) \simeq pk\left(plus\left({\sim}sk1, {\sim}sk2\right)\right)\\
    &comb\left(pdec\left(c,sk1\right), pdec\left(c,sk2\right)\right) \simeq dec\left(c, plus\left(sk1,sk2\right)\right) 
\end{align*}

The $enc$, $dec$ and $pk$ functions are defined to model standard asymmetric encryption, where the public-key $pk$ of a secret-key $sk$ is given as $pk = pk(sk)$. The encrypt function $enc(m,pk)$ takes a message and a public-key and yields a ciphertext, and the decryption function $dec(c,sk)$ takes a ciphertext and a secret-key. The message can be recovered if, and only if: $dec(enc(m,pk(sk)), sk) = m$.

The $pdec(c,sk)$ function models partial decryption. Partial decryptions can be combined using the $comb$ function, that given two partial decryptions $pdec(c,x)$ and $pdec(c,y)$, yields a decryption of the cipher with the sum of the private keys $dec(c,plus(x,y))$. This gives a set of primitives, where an encrypted message $enc(m,pk)$, with the joint public-key $comb(pk(sk1), pk(sk2))$, can only be recovered by partially decrypting with both $sk1$ and $sk2$. This is exactly the abstract definition of Distributed ElGamal, as presented in section~\ref{sec:deg}.

\subsubsection{Defining the Actors}
Next we model the behaviour of the different actors of the protocol. The client actor is omitted in this model, as it simply relays messages between a \gls{server} and \gls{authenticator}.

\paragraph{Registration rule}
Registration is modelled as one rule, where two new fresh long-term keys (ltk) for the \gls{authenticator} and \gls{sibling}, are fixed and persisted for later retrieval with the $!Ltk$ predicate. The key is saved with a relation to the device and the server, such that devices can have multiple keys for different \glspl{server}. A joint public-key is set as the combination of the public-key of the two ltk's. The public-key is persisted with the $!Pk$ predicate with a relation to the three actors. Finally the public-key is outputted and an event of the registration is recorded.
\begin{equation} \tag{registration}
\begin{split}
& \plet{pk = comb(pk({\sim}n),  pk({\sim}y))}\\
& \qquad Fr({\sim}x),~Fr({\sim}y)\\
& \ifarrow[Register(\$S, \$A, \$As)]\\
&\qquad    !Ltk(\$A, \$S, {\sim}x),~!Ltk(\$As, \$S, {\sim}y),\\
&\qquad    !Pk(\$S, \$A, \$As, pk),~Out(pk)
\end{split}
\end{equation}



\paragraph{\gls{server} rules}
The \glspl{server} behavior is modeled in two rules. The first rule initially fixes a new fresh nonce $~n$ and encrypts it with the public-key of a given \gls{authenticator} and \gls{sibling}. It stores the nonce with the $Server$ predicate and then outputs the challenge.
\begin{equation} \tag{server-init}
\begin{split}
& Fr({\sim}n),~!Pk(\$S, \$A, \$As, pk) \ifarrow[]\\
& Server(pk, {\sim}n),~Out(enc({\sim}n,pk))
\end{split}
\end{equation}


The second server rule receives a response to the challenge, and thus takes as input a nonce $n$. The nonce is pattern-matched with the nonce given from the previous rule, and thus the rule can only be used if the two nonces match. An event is then fired, indicating that  authentication between the \gls{server}, \gls{authenticator} and \gls{sibling} was successfully achieved.
\begin{equation} \tag{server-done}
\begin{split}
& In(n),~Server(pk, n),~!Pk(\$S, \$A, \$As, pk) \\
& \ifarrow[ Auth(\$S, \$A, \$As, enc(n,pk) ] \emptyset 
\end{split}
\end{equation}

\paragraph{\gls{authenticator} rules}
The \glspl{authenticator} behavior is also modeled as two rules. The first rule receives a challenge $c$, and saves the challenge as state with the $Authenticator$ predicate. The challenge is then outputted to the $Secure$ predicate, which is used to model communication with its \gls{sibling}. This allows us to model authentic and secure communication between the actors.
\begin{equation} \tag{authen-init}
\begin{split}
& \plet{c = enc({\sim}n, pk)} \\
& In(c) \ifarrow \\
& Secure(c),~Authenticator(\$A,c)
\end{split}
\end{equation}

In this rule we had to limit the input, to only accept ciphers encrypted with its public-key, as Tamarin will otherwise try to compute all states where the \gls{authenticator} is given an arbitrary value. This is a reasonable limitation as all valid messages and ciphers belong to the same space $\mathbb{G}$. The input is limited by pattern matching.

The second rule takes as input a partial encryption from the secure channel, its persisted ltk, and the challenge that was received in the previous rule. An event that the \gls{authenticator} answered the challenge is fired, and a combination of the partial encryption received from its \gls{sibling} and its own partial encryption (yielding $n$ if correct) is then outputted. 
\begin{equation} \tag{authen-done}
\begin{split}
& Secure(c'_{As}),~!Ltk(\$A, \$S, x),~Authenticator(\$A,c) \\
& \ifarrow[ Acted(\$A, c) ] \\
& Secure(comb(pdec(c,x), c'_{As}))
\end{split}
\end{equation}

\paragraph{\gls{sibling} rule}
The sibling is modeled as a single rule that on input of a challenge $c$ retrieves its persisted ltk, fires an event that it answered the request, and outputs a partial decryption of the cipher.
\begin{equation} \tag{sibling}
\begin{split}
& Secure(c),~!Ltk(\$As, \$S, y) \\
& \ifarrow[ Acted(\$As, c) ] \\
& Secure(pdec(c,y))
\end{split}
\end{equation}

\subsubsection{Modelling the Adversary}
In Tamarin the adversary can observe and intercept any message sent using the default $In$ and $Out$ predicates. Furthermore, the adversary can utilize any observed information to fabricate and send new messages. We furthermore model rules allowing the adversary to reveal keys, and to both break authenticity and secrecy on the $Secure$ channel. In contrary to the default channel we however log if any of these rules are utilized.
\begin{align} 
& \tag{reveal} !Ltk(d, \$S, {\sim}ltk) \ifarrow[ LtkReveal(d, \$S) ] Out({\sim}ltk) \\
& \tag{authentic} In(m) \ifarrow[ AuthenticityBroken() ] Secure(m) \\
& \tag{secret} Secure(m) \ifarrow[ SecrecyBroken() ] Out(m)
\end{align}

\subsection{Proving Injective Agreement and Unforgeability}

This section will present theorems to prove that our protocol achieves injective agreement for adversaries capable of \textit{Strong \textit{Internal Observation}}, if the communication between \gls{authenticator} and \gls{sibling} is authentic.

Before we can state the theorems we first establish a few definitions. First of all we need a definition for when an adversary either compromised a key or infiltrated the secure channel. 

\begin{definition}
We say that an adversary compromised a long-term key of $d$ for $S$ before $i$, if there exists events $LtkReveal(d,S)$ at time $j$ with $j < i$.
\end{definition}

\begin{definition}
We say that secrecy is interact at time $i$, if there does not exists an event $SecrecyBroken()$ at time $j$ with $j < i$.
\end{definition}

\begin{definition}
We say that authenticity is interact at time $i$, if there does not exists an event $AuthenticityBroken()$ at time $j$ with $j < i$.
\end{definition}

Furthermore we need a definition for when an honest device completed a run of the protocol.
\begin{definition}
We say that a device $d$ acted on a challenge $c$ before time $i$, if there exists an event $Acted(d,c)$ at time $j$ with $j < i$.
\end{definition}

An implication of the atomicity of both authenticator and sibling rules as well as the definition of `acted',  is that a device is either acting or not acting in a run of the protocol. In practice, things are not so binary. An adversary could, for example, compromise the device, and not be able to obtain the key, but instead always accept explicit consent request without any user interaction. This could lead to attacks, but is not entailed by the model. This will be revisited in the discussion (section \ref{ch:discussion}).
\subsubsection{Proving Unforgeability}
In the following, we state a definition of unforgeability in the presence of adversaries capable of \textit{Internal Observation}. We define \textit{Internal Observation} to be slightly weaker than \textit{Strong Internal Observation} and now assume that messages between \gls{authenticator} and \gls{sibling} are authentic. 

\begin{theorem}
Our protocol has unforgeability in the presence of adaptive adversaries capable of \textit{Internal Observation}, if for all authentication events $Auth(S,A,As,c)$ at time i, where authenticity is still intact at $i$, then either:
\begin{enumerate}
    \item Both authenticator and sibling acted on $c$ before $i$, or
    \item An adversary compromised the long-term keys of both $A$ and $As$ for $S$ before $i$.
\end{enumerate}
\end{theorem}

The theorem is proven and holds in the presented model. Furthermore, the definitions of unforgeability, as presented in the previous section, is revisited. In the symbolic model of the protocol, the adversarial capabilities are defined, as shown in table~\ref{table:adversaries}. Note that the use of `Observation' is not strictly correct in this model as we allow adversaries to also synthesize and send messages through $Out$ and $Authentic$.

As expected, unforgeability can be proven in the presence of adversaries capable of \textit{Weak External Observation}, \textit{Weak Internal Observation} and \textit{Strong External Observation}. See appendix~\ref{ch:tamarin}.

\begin{table}[bth]
\centering
%\resizebox{\linewidth}{!}{
% \setlength\tabcolsep{1.8pt}
\begin{tabular}{r|cccc}
& \rot{\textit{In/Out}}
& \rot{\textit{Secret}}
& \rot{\textit{Authentic}}
& \rot{\textit{LtkReveal}}\\ \hline

\textit { Weak External Observation }   & \CIRCLE & & &  \\ \hline
\textit { Weak Internal Observation }   & \CIRCLE & & & \CIRCLE \\ \hline
\textit { Strong External Observation } & \CIRCLE & \CIRCLE & \CIRCLE &  \\ \hline
\textit { Strong Internal Observation } & \CIRCLE & \CIRCLE & \CIRCLE & \CIRCLE \\ \hline
\textit { Internal Observation }        & \CIRCLE & \CIRCLE & & \CIRCLE \\ \hline

    \end{tabular}
%}
\caption{Definitions of adversarial capabilities}
\label{table:adversaries}
\end{table}

Furthermore, we confirm that an attack for unforgeability is also found in this model for adversaries capable of \textit{Strong Internal Observation}, although a slightly different strategy is chosen as the adversary compromises the sibling instead of the authenticator. The attack trace is shown in appendix~\ref{ch:attack}.

\subsubsection{Proving Injective Agreement}
We stated in the beginning of the protocol design (chapter~\ref{ch:protocol}) that authentication was achieved if and only if injective agreement was achieved. We will now present the definition of injective agreement in the presence of adversaries capable of \textit{Internal Observation} as proving in the model:

\begin{theorem}
Our protocol achieves injective agreement in the presence of adaptive adversaries capable of \textit{Internal Observation}, if for all authentication events $a_1 = Auth(S,A,As,c)$ at time $i$, where authenticity is still intact $i$, then either:
\begin{enumerate}
    \item Both \gls{authenticator} and \gls{sibling} acted on $c$ before $i$, and for all authentication events $a_2 = Auth(S,\cdot,\cdot,c)$, $a_1$ is equal to $a_2$, or
    \item An adversary compromised the long-term keys of both $A$ and $As$ for $S$ before $i$.
\end{enumerate}
\end{theorem}

\subsubsection{Proving Actor Involvement}\label{sec:involvement}

Lastly we will prove that, unless the keys of both \gls{authenticator} and \gls{sibling} are revealed, then either \gls{authenticator} or \gls{sibling} acted in the protocol run. This is important as the participation of, at least one device, allows the user to 1) potentially be made aware of active authentication sessions, and 2) be able to lockdown the device and effectively stop all active authentications. The following definition is proven in the symbolic model:

\begin{theorem}
For all authentication events $a_1 = Auth(S,A,As,c)$ at time $i$, then either:
\begin{enumerate}
    \item The \gls{authenticator} or \gls{sibling} acted on $c$ before $i$, or 
    \item An adversary compromised the long-term keys of both $A$ and $As$ for $S$ before $i$.
\end{enumerate}
\end{theorem}

\begin{comment}

\begin{itemize}
\item Authentication\_Possible (exists-trace): verified (7 steps)
\item Unforgeability\_Weak\_External\_Observation (all-traces): verified (16 steps)
\item Unforgeability\_Strong\_External\_Observation (all-traces): verified (61 steps)
\item Unforgeability\_Weak\_Internal\_Observation (all-traces): verified (21 steps)
\item Unforgeability\_Strong\_Internal\_Observation (all-traces): falsified - found trace (8 steps)
\item Unforgeability\_Strong\_Internal\_Observation\_Only\_Authentic (all-traces): verified (21 steps)
\item Unforgeability\_Without\_Devices\_Only\_If\_Both\_Compromised (all-traces): verified (74 steps)
\item Client\_Auth\_Injective (all-traces): verified (25 steps)    
\end{itemize}

\end{comment}


\begin{comment}
This section should show that:
\begin{itemize}
    \item That proposition 1 and 2 and conjecture 1 holds in the model, and show that proposition 3 does not hold in the model.
    \item That an adversary most compromise at least one key to forge authentication. 
    \item If we assume that messages between authenticator and sibling is authentic / secret, then our scheme is unforgeable under strong internal observation.
\end{itemize}
\end{comment}